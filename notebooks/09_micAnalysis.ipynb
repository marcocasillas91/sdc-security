{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d2a205-e7bb-4cfc-930a-80826d2c83fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "\t\taccuracy_score as acc_score,\n",
    "\t\trecall_score   as recall,\n",
    "\t\tconfusion_matrix,\n",
    "        mean_squared_error as mse, \n",
    "        r2_score\n",
    "\t\t)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#MODELS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "#import xgboost as xgb\n",
    "#xgb_regressor = xgb.XGBRegressor()\n",
    "from sklearn.neural_network import MLPRegressor  # Use MLPRegressor for regression\n",
    "#from minepy import MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f328f-f697-449c-b59e-f66829f64180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Path\n",
    "#Insert your local repo path to file\n",
    "path_home = \"D:\\Archivos\\Social Data Challenge\\data\\grids\\quarter_samples\"\n",
    "\n",
    "csv_100 = pd.read_csv(path_home + '\\grid_100_htmp.csv')\n",
    "csv_500 = pd.read_csv(path_home + '\\grid_500_htmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59933fa3-96f0-40d1-b8bc-14b66c8293e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2b581-e0c0-4c23-81b4-a84c41903af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x =  csv_100.iloc[:, 1:-2]\n",
    "y_crime23q1 = csv_100['crime23q1']\n",
    "y_sample23q1 = csv_100['sample23q1']\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "#x_1=pd.DataFrame(X_scaled, columns = X.columns)\n",
    "\n",
    "#X_scaled[X_scaled.sample22q2 != 0]\n",
    "#x[x.crime22q4 >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8274ba-fd04-41a6-ad2d-3a7ebde2d132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "#y = y_crime23q1\n",
    "y= y_sample23q1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad974d2-ebbe-43e6-a265-16ffd2716692",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Maximal Information Coefficient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1a447-8ff5-4f81-8acc-e28fb2eff4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel\n",
    "!pip install --upgrade setuptools\n",
    "!pip3 install minepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594b810-7233-4aff-8a62-3578dcf1ef07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from minepy import MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344648c3-ec04-4e7e-991b-0f37748b2a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x.iloc[:,2]\n",
    "x.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57d137-444d-4e15-bda9-ffe1af6c0e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14ad45-de61-4811-8608-5c769f255cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_scaled = pd.DataFrame(X_scaled, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e791af-5b15-4f85-b733-611fd6b68377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412b941-5ccb-4fa9-a516-d3b8392ca7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the MINE object\n",
    "\n",
    "# Create a dictionary to store MIC scores for each column\n",
    "mic_scores = {}\n",
    "\n",
    "mine = MINE(alpha=0.6, c=15, est=\"mic_approx\")\n",
    "subset_data = x_scaled.copy()\n",
    "            \n",
    "# Iterate through columns in the subset_data DataFrame\n",
    "for column_name in subset_data.columns:\n",
    "    # Calculate MIC score for the column\n",
    "    mine.compute_score(subset_data[column_name], y)  # Replace 'target_column' with your target column\n",
    "    mic_score = mine.mic()\n",
    "\n",
    "    # Store the MIC score in the dictionary\n",
    "    mic_scores[column_name] = mic_score\n",
    "\n",
    "# Sort the dictionary by MIC scores in descending order\n",
    "sorted_mic_scores = dict(sorted(mic_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "count = 1\n",
    "# Print the sorted MIC scores\n",
    "for column_name, mic_score in sorted_mic_scores.items():\n",
    "    print(f\"{count}. {column_name}: {mic_score:.4f}\")\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b3c7f-d556-4fc2-9f0a-83b55fc58694",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since the Maximal Information Coefficient variables belong to the 'sample' columns, we create a sub sataset with only those columns to test the accuracy of the Linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9785c37-acf0-4947-a120-9916f212feff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled= True\n",
    "mic = False\n",
    "pca_flag = False\n",
    "pca_components = 1\n",
    "df = csv_100.copy()\n",
    "\n",
    "x =  df.iloc[:, 1:-2]\n",
    "\n",
    "if scaled :\n",
    "    scaler = StandardScaler()\n",
    "    x =  pd.DataFrame(scaler.fit_transform(x), columns = x.columns)\n",
    "\n",
    "\n",
    "if mic:\n",
    "    mic_cols= [col for col in x.columns if col.startswith('sample')]\n",
    "    x= x[mic_cols]\n",
    "\n",
    "if pca_flag:\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    pca.fit(x)\n",
    "    x=pd.DataFrame(pca.transform(x))\n",
    "    \n",
    "#x_to_use= x_scaled\n",
    "\n",
    "y_crime23q1 = df['crime23q1']\n",
    "y_sample23q1 = df['sample23q1']\n",
    "y =  y_crime23q1\n",
    "\n",
    "###########\n",
    "###########\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f41a65-87b9-4a6f-bfd0-f85e20c16f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf139f5-6c65-4e8a-90c7-4d39ee09175a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "#    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor()#,\n",
    "    #'Support Vector Regressor': SVR(),\n",
    "    #'Perceptron': Perceptron(),\n",
    "    #'Neural Network': MLPRegressor()\n",
    "    # Add more regressor models and hyperparameters here\n",
    "}\n",
    "\n",
    "# Define a parameter grid for each model\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Random Forest Regressor': {\n",
    "        'n_estimators': [500],\n",
    "        'max_depth': [30]\n",
    "    }        \n",
    "        # Add more hyperparameters to tune here\n",
    "    #,\n",
    "    'Support Vector Regressor': {\n",
    "       'kernel': ['linear', 'rbf'],\n",
    "       'C': [0.1, 1, 10]#,\n",
    "        # Add more hyperparameters to tune here\n",
    "    },\n",
    "    'Perceptron': {\n",
    "        'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        # Add more hyperparameters to tune here\n",
    "    },\n",
    "#    'Neural Network': {\n",
    "#        'hidden_layer_sizes': [(50,), (100, 50), (100, 100, 50)],\n",
    "#        'activation': ['relu', 'tanh'],\n",
    "#        'alpha': [0.0001, 0.001, 0.01],\n",
    "        # Add more hyperparameters to tune here\n",
    "    #}\n",
    "    # Add parameter grids for other models\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a53e59-3f55-4ab2-abc3-01c4fd73084a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the best models and their scores\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "best_parameters = {}\n",
    "\n",
    "\n",
    "# Iterate through the models and perform grid search\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and its score\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = -grid_search.best_score_  # Negative MSE\n",
    "    best_param = grid_search.best_params_\n",
    "\n",
    "    \n",
    "    # Store the best model and score\n",
    "    best_models[model_name] = best_model\n",
    "    best_scores[model_name] = best_score\n",
    "    best_parameters[model_name] = best_param\n",
    "    \n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame({'Model': list(best_models.keys()), \n",
    "                           'Best Parameters': list(best_parameters.values()),\n",
    "                           'Best MSE Score':  list(best_scores.values())})\n",
    "\n",
    "results_df.sort_values(by='Best MSE Score', ascending=True, inplace=True)\n",
    "print(results_df)\n",
    "\n",
    "print(best_models)\n",
    "print(best_scores)\n",
    "print(best_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb2450-f734-4f50-9f29-df56eb88667e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32630e-99a8-4fab-953d-9deaee398b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2719aac-71f6-418d-ac7e-1d2e5f636183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
